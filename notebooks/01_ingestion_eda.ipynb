{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f2d190c",
   "metadata": {},
   "source": [
    "# 01 â€” Data Ingestion & Overview\n",
    "Notes:\n",
    "- Objective: locally stage raw datasets, inspect columns and sample rows, basic cleaning utilities.\n",
    "- Outputs: processed master table saved to data/processed/master_table.parquet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a8bc184a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data path: C:\\Users\\abanu\\Documents\\T-IQ\\data\\raw\n",
      "Processed data path: C:\\Users\\abanu\\Documents\\T-IQ\\data\\processed\n"
     ]
    }
   ],
   "source": [
    "# Notebook 01: Data Loading & Initial Cleaning (Polished)\n",
    "# T-IQ Project\n",
    "\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import json\n",
    "import re\n",
    "\n",
    "# Set paths\n",
    "RAW = Path(r\"C:\\Users\\abanu\\Documents\\T-IQ\\data\\raw\")\n",
    "PROCESSED = Path(RAW.parent / \"processed\")\n",
    "PROCESSED.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "print(\"Raw data path:\", RAW)\n",
    "print(\"Processed data path:\", PROCESSED)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3eebed61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attrition dataset loaded, shape: (1470, 35)\n"
     ]
    }
   ],
   "source": [
    "attrition_path = RAW / \"WA_Fn-UseC_-HR-Employee-Attrition.csv\"\n",
    "\n",
    "if attrition_path.exists():\n",
    "    attrition = pd.read_csv(attrition_path)\n",
    "    print(\"Attrition dataset loaded, shape:\", attrition.shape)\n",
    "else:\n",
    "    print(\"Attrition dataset not found!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8755a537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1470 entries, 0 to 1469\n",
      "Data columns (total 35 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   Age                       1470 non-null   int64 \n",
      " 1   Attrition                 1470 non-null   object\n",
      " 2   BusinessTravel            1470 non-null   object\n",
      " 3   DailyRate                 1470 non-null   int64 \n",
      " 4   Department                1470 non-null   object\n",
      " 5   DistanceFromHome          1470 non-null   int64 \n",
      " 6   Education                 1470 non-null   int64 \n",
      " 7   EducationField            1470 non-null   object\n",
      " 8   EmployeeCount             1470 non-null   int64 \n",
      " 9   EmployeeNumber            1470 non-null   int64 \n",
      " 10  EnvironmentSatisfaction   1470 non-null   int64 \n",
      " 11  Gender                    1470 non-null   object\n",
      " 12  HourlyRate                1470 non-null   int64 \n",
      " 13  JobInvolvement            1470 non-null   int64 \n",
      " 14  JobLevel                  1470 non-null   int64 \n",
      " 15  JobRole                   1470 non-null   object\n",
      " 16  JobSatisfaction           1470 non-null   int64 \n",
      " 17  MaritalStatus             1470 non-null   object\n",
      " 18  MonthlyIncome             1470 non-null   int64 \n",
      " 19  MonthlyRate               1470 non-null   int64 \n",
      " 20  NumCompaniesWorked        1470 non-null   int64 \n",
      " 21  Over18                    1470 non-null   object\n",
      " 22  OverTime                  1470 non-null   object\n",
      " 23  PercentSalaryHike         1470 non-null   int64 \n",
      " 24  PerformanceRating         1470 non-null   int64 \n",
      " 25  RelationshipSatisfaction  1470 non-null   int64 \n",
      " 26  StandardHours             1470 non-null   int64 \n",
      " 27  StockOptionLevel          1470 non-null   int64 \n",
      " 28  TotalWorkingYears         1470 non-null   int64 \n",
      " 29  TrainingTimesLastYear     1470 non-null   int64 \n",
      " 30  WorkLifeBalance           1470 non-null   int64 \n",
      " 31  YearsAtCompany            1470 non-null   int64 \n",
      " 32  YearsInCurrentRole        1470 non-null   int64 \n",
      " 33  YearsSinceLastPromotion   1470 non-null   int64 \n",
      " 34  YearsWithCurrManager      1470 non-null   int64 \n",
      "dtypes: int64(26), object(9)\n",
      "memory usage: 402.1+ KB\n",
      "Missing values per column:\n",
      " Age                         0\n",
      "Attrition                   0\n",
      "BusinessTravel              0\n",
      "DailyRate                   0\n",
      "Department                  0\n",
      "DistanceFromHome            0\n",
      "Education                   0\n",
      "EducationField              0\n",
      "EmployeeCount               0\n",
      "EmployeeNumber              0\n",
      "EnvironmentSatisfaction     0\n",
      "Gender                      0\n",
      "HourlyRate                  0\n",
      "JobInvolvement              0\n",
      "JobLevel                    0\n",
      "JobRole                     0\n",
      "JobSatisfaction             0\n",
      "MaritalStatus               0\n",
      "MonthlyIncome               0\n",
      "MonthlyRate                 0\n",
      "NumCompaniesWorked          0\n",
      "Over18                      0\n",
      "OverTime                    0\n",
      "PercentSalaryHike           0\n",
      "PerformanceRating           0\n",
      "RelationshipSatisfaction    0\n",
      "StandardHours               0\n",
      "StockOptionLevel            0\n",
      "TotalWorkingYears           0\n",
      "TrainingTimesLastYear       0\n",
      "WorkLifeBalance             0\n",
      "YearsAtCompany              0\n",
      "YearsInCurrentRole          0\n",
      "YearsSinceLastPromotion     0\n",
      "YearsWithCurrManager        0\n",
      "dtype: int64\n",
      "Department unique values: ['Sales' 'Research & Development' 'Human Resources']\n",
      "JobRole unique values: ['Sales Executive' 'Research Scientist' 'Laboratory Technician'\n",
      " 'Manufacturing Director' 'Healthcare Representative' 'Manager'\n",
      " 'Sales Representative' 'Research Director' 'Human Resources']\n",
      "EducationField unique values: ['Life Sciences' 'Other' 'Medical' 'Marketing' 'Technical Degree'\n",
      " 'Human Resources']\n",
      "Gender unique values: ['Female' 'Male']\n",
      "MaritalStatus unique values: ['Single' 'Married' 'Divorced']\n",
      "Attrition cleaned and saved.\n"
     ]
    }
   ],
   "source": [
    "# Basic info\n",
    "attrition.info()\n",
    "attrition.describe()\n",
    "\n",
    "# Missing values\n",
    "print(\"Missing values per column:\\n\", attrition.isnull().sum())\n",
    "\n",
    "# Drop duplicates\n",
    "attrition = attrition.drop_duplicates()\n",
    "\n",
    "# Map Attrition to 0/1\n",
    "attrition['Attrition'] = attrition['Attrition'].map({'Yes':1, 'No':0})\n",
    "\n",
    "# Preview unique categorical values\n",
    "for col in ['Department','JobRole','EducationField','Gender','MaritalStatus']:\n",
    "    if col in attrition.columns:\n",
    "        print(f\"{col} unique values: {attrition[col].unique()}\")\n",
    "\n",
    "# Save processed\n",
    "attrition.to_csv(PROCESSED / \"attrition_clean.csv\", index=False)\n",
    "\n",
    "# Optional: save sample for quick testing\n",
    "attrition.sample(100).to_csv(PROCESSED / \"attrition_sample.csv\", index=False)\n",
    "print(\"Attrition cleaned and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "91177f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HRMS summary loaded, shape: (10000, 11)\n"
     ]
    }
   ],
   "source": [
    "hrms_summary_path = RAW / \"hrms_synth_summary.csv\"\n",
    "\n",
    "if hrms_summary_path.exists():\n",
    "    hrms_summary = pd.read_csv(hrms_summary_path)\n",
    "    print(\"HRMS summary loaded, shape:\", hrms_summary.shape)\n",
    "else:\n",
    "    print(\"HRMS summary dataset not found!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2bb256e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 11 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   employee_id         10000 non-null  object \n",
      " 1   name                10000 non-null  object \n",
      " 2   department          10000 non-null  object \n",
      " 3   job_role            10000 non-null  object \n",
      " 4   location            10000 non-null  object \n",
      " 5   current_salary      10000 non-null  int64  \n",
      " 6   satisfaction_score  10000 non-null  float64\n",
      " 7   engagement_score    10000 non-null  float64\n",
      " 8   num_skills          10000 non-null  int64  \n",
      " 9   years_at_company    10000 non-null  int64  \n",
      " 10  trainings_count     10000 non-null  int64  \n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 859.5+ KB\n",
      "Missing values:\n",
      " employee_id           0\n",
      "name                  0\n",
      "department            0\n",
      "job_role              0\n",
      "location              0\n",
      "current_salary        0\n",
      "satisfaction_score    0\n",
      "engagement_score      0\n",
      "num_skills            0\n",
      "years_at_company      0\n",
      "trainings_count       0\n",
      "dtype: int64\n",
      "  employee_id             name department                  job_role  \\\n",
      "0   EMP000001     Vikram Singh         HR            Data Scientist   \n",
      "1   EMP000002      Karan Patel  Marketing            Data Scientist   \n",
      "2   EMP000003  Vikram Malhotra  Marketing  Senior Software Engineer   \n",
      "3   EMP000004   Siddharth Khan         HR               ML Engineer   \n",
      "4   EMP000005       Priya Nair      Legal               ML Engineer   \n",
      "\n",
      "           location  current_salary  satisfaction_score  engagement_score  \\\n",
      "0     New York, USA         4544478                0.78              0.80   \n",
      "1    Chennai, India         5180268                0.71              0.93   \n",
      "2    Chennai, India         2589268                0.81              0.56   \n",
      "3  Bengaluru, India         1321856                0.43              0.95   \n",
      "4            Remote         4371479                0.41              0.70   \n",
      "\n",
      "   num_skills  years_at_company  trainings_count  \n",
      "0           7                12                0  \n",
      "1           8                 7                4  \n",
      "2           6                 3                3  \n",
      "3           7                15                3  \n",
      "4           4                 7                2  \n",
      "HRMS summary cleaned and saved.\n"
     ]
    }
   ],
   "source": [
    "# Basic info\n",
    "hrms_summary.info()\n",
    "print(\"Missing values:\\n\", hrms_summary.isnull().sum())\n",
    "\n",
    "# Drop duplicates\n",
    "hrms_summary = hrms_summary.drop_duplicates()\n",
    "\n",
    "# Preview top columns\n",
    "print(hrms_summary.head())\n",
    "\n",
    "# Save processed\n",
    "hrms_summary.to_csv(PROCESSED / \"hrms_summary_clean.csv\", index=False)\n",
    "print(\"HRMS summary cleaned and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "715b5144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job Descriptions loaded, shape: (10000, 12)\n"
     ]
    }
   ],
   "source": [
    "jobs_path = RAW / \"job_descriptions.csv\"\n",
    "\n",
    "if jobs_path.exists():\n",
    "    jobs = pd.read_csv(jobs_path)\n",
    "    print(\"Job Descriptions loaded, shape:\", jobs.shape)\n",
    "else:\n",
    "    print(\"Job Descriptions dataset not found!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bfabebe2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Job descriptions cleaned and saved.\n"
     ]
    }
   ],
   "source": [
    "if 'job_text' in jobs.columns:\n",
    "    jobs['job_text'] = jobs['job_text'].str.lower().str.replace(r'\\s+', ' ', regex=True)\n",
    "    jobs['job_text'] = jobs['job_text'].str.replace(r'[^a-z0-9 ,.]', '', regex=True)\n",
    "\n",
    "jobs.to_csv(PROCESSED / \"job_descriptions_clean.csv\", index=False)\n",
    "print(\"Job descriptions cleaned and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7e252e32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glassdoor reviews loaded, shape: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "reviews_path = RAW / \"glassdoor_reviews.csv\"\n",
    "\n",
    "if reviews_path.exists():\n",
    "    reviews = pd.read_csv(reviews_path)\n",
    "    print(\"Glassdoor reviews loaded, shape:\", reviews.shape)\n",
    "else:\n",
    "    print(\"Glassdoor reviews dataset not found!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3088d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glassdoor reviews cleaned and saved.\n"
     ]
    }
   ],
   "source": [
    "text_cols = ['review_text', 'pros', 'cons']\n",
    "for col in text_cols:\n",
    "    if col in reviews.columns:\n",
    "        reviews[col] = reviews[col].astype(str).str.lower().str.replace(r'\\s+', ' ', regex=True)\n",
    "        reviews[col] = reviews[col].str.replace(r'[^a-z0-9 ,.]', '', regex=True)\n",
    "\n",
    "reviews.to_csv(PROCESSED / \"glassdoor_reviews_clean.csv\", index=False)\n",
    "print(\"Glassdoor reviews cleaned and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0fc12ed4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumes metadata loaded, shape: (2484, 4)\n"
     ]
    }
   ],
   "source": [
    "resumes_path = RAW / \"resumes/Resume/Resume.csv\"\n",
    "\n",
    "if resumes_path.exists():\n",
    "    resumes = pd.read_csv(resumes_path)\n",
    "    print(\"Resumes metadata loaded, shape:\", resumes.shape)\n",
    "else:\n",
    "    print(\"Resumes dataset not found!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99501e89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resumes metadata cleaned and saved.\n"
     ]
    }
   ],
   "source": [
    "if 'skills' in resumes.columns:\n",
    "    resumes['skills'] = resumes['skills'].astype(str).str.lower().str.replace(r'\\s+', ' ', regex=True)\n",
    "    resumes['skills'] = resumes['skills'].str.replace(r'[^a-z0-9 ,]', '', regex=True)\n",
    "\n",
    "resumes.to_csv(PROCESSED / \"resumes_clean.csv\", index=False)\n",
    "print(\"Resumes metadata cleaned and saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "361d56a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HRMS JSON loaded, total records: 10000\n",
      "Flattened HRMS shape: (10000, 26)\n",
      "HRMS JSON flattened and saved.\n"
     ]
    }
   ],
   "source": [
    "hrms_json_path = RAW / \"hrms_synth.json\"\n",
    "\n",
    "if hrms_json_path.exists():\n",
    "    with open(hrms_json_path, \"r\") as f:\n",
    "        hrms_json = json.load(f)\n",
    "    print(\"HRMS JSON loaded, total records:\", len(hrms_json))\n",
    "\n",
    "    # Flatten\n",
    "    hrms_flat = pd.json_normalize(hrms_json)\n",
    "    print(\"Flattened HRMS shape:\", hrms_flat.shape)\n",
    "    hrms_flat.to_csv(PROCESSED / \"hrms_json_flattened.csv\", index=False)\n",
    "    print(\"HRMS JSON flattened and saved.\")\n",
    "else:\n",
    "    print(\"HRMS JSON dataset not found!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f7cf1046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All datasets loaded, cleaned, sanity-checked, and saved in: C:\\Users\\abanu\\Documents\\T-IQ\\data\\processed\n"
     ]
    }
   ],
   "source": [
    "print(\"All datasets loaded, cleaned, sanity-checked, and saved in:\", PROCESSED)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
