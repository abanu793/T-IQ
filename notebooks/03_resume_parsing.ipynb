{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da9cfa43",
   "metadata": {},
   "source": [
    "Resume parsing notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0861bc62",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\abanu\\Documents\\T-IQ\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import html\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "from IPython.display import display\n",
    "\n",
    "tqdm.pandas()  # enable progress bars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6dbad81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>employee_id</th>\n",
       "      <th>resume_text</th>\n",
       "      <th>resume_html</th>\n",
       "      <th>resume_category</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>...</th>\n",
       "      <th>Unnamed: 162</th>\n",
       "      <th>Unnamed: 163</th>\n",
       "      <th>Unnamed: 164</th>\n",
       "      <th>Unnamed: 165</th>\n",
       "      <th>Unnamed: 166</th>\n",
       "      <th>Unnamed: 167</th>\n",
       "      <th>Unnamed: 168</th>\n",
       "      <th>Resume_str</th>\n",
       "      <th>Resume_html</th>\n",
       "      <th>Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16852973</td>\n",
       "      <td>HR ADMINISTRATOR/MARKETING ASSOCIATE\\...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargin...</td>\n",
       "      <td>HR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22323967</td>\n",
       "      <td>HR SPECIALIST, US HR OPERATIONS      ...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargin...</td>\n",
       "      <td>HR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33176873</td>\n",
       "      <td>HR DIRECTOR       Summary      Over 2...</td>\n",
       "      <td>&lt;div class=\"fontsize fontface vmargins hmargin...</td>\n",
       "      <td>HR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 172 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  employee_id                                        resume_text  \\\n",
       "0    16852973           HR ADMINISTRATOR/MARKETING ASSOCIATE\\...   \n",
       "1    22323967           HR SPECIALIST, US HR OPERATIONS      ...   \n",
       "2    33176873           HR DIRECTOR       Summary      Over 2...   \n",
       "\n",
       "                                         resume_html resume_category  \\\n",
       "0  <div class=\"fontsize fontface vmargins hmargin...              HR   \n",
       "1  <div class=\"fontsize fontface vmargins hmargin...              HR   \n",
       "2  <div class=\"fontsize fontface vmargins hmargin...              HR   \n",
       "\n",
       "  Unnamed: 4 Unnamed: 5 Unnamed: 6 Unnamed: 7 Unnamed: 8 Unnamed: 9  ...  \\\n",
       "0        NaN        NaN        NaN        NaN        NaN        NaN  ...   \n",
       "1        NaN        NaN        NaN        NaN        NaN        NaN  ...   \n",
       "2        NaN        NaN        NaN        NaN        NaN        NaN  ...   \n",
       "\n",
       "  Unnamed: 162 Unnamed: 163 Unnamed: 164 Unnamed: 165 Unnamed: 166  \\\n",
       "0          NaN          NaN          NaN          NaN          NaN   \n",
       "1          NaN          NaN          NaN          NaN          NaN   \n",
       "2          NaN          NaN          NaN          NaN          NaN   \n",
       "\n",
       "  Unnamed: 167 Unnamed: 168 Resume_str Resume_html Category  \n",
       "0          NaN          NaN       None        None     None  \n",
       "1          NaN          NaN       None        None     None  \n",
       "2          NaN          NaN       None        None     None  \n",
       "\n",
       "[3 rows x 172 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    2710.0\n",
      "mean        4.0\n",
      "std         0.0\n",
      "min         4.0\n",
      "25%         4.0\n",
      "50%         4.0\n",
      "75%         4.0\n",
      "max         4.0\n",
      "Name: len_text, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Path to CSV\n",
    "csv_path = r\"C:\\Users\\abanu\\Documents\\T-IQ\\data\\raw\\resumes\\Resume\\Resume.csv\"\n",
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Normalize column names\n",
    "df.columns = [c.strip() for c in df.columns]\n",
    "\n",
    "# Ensure canonical columns exist\n",
    "for col in ['Resume_str','Resume_html','Category']:\n",
    "    if col not in df.columns:\n",
    "        df[col] = None\n",
    "\n",
    "# Display top rows\n",
    "display(df.head(3))\n",
    "\n",
    "# Quick stats\n",
    "df['len_text'] = df['Resume_str'].astype(str).map(len)\n",
    "print(df['len_text'].describe())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5814e5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Clean HTML to plain text\n",
    "def clean_resume_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # Use BeautifulSoup to remove HTML\n",
    "    text = BeautifulSoup(text, \"lxml\").get_text(separator=\" \")\n",
    "    \n",
    "    # Remove leftover HTML fragments\n",
    "    text = re.sub(r\"</?\\w+[^>]*>\", \" \", text)\n",
    "    \n",
    "    # Remove bullets and weird characters\n",
    "    text = re.sub(r\"[\\•\\●\\►\\▪\\□\\·]\", \" \", text)\n",
    "    \n",
    "    # Normalize whitespace\n",
    "    text = \" \".join(text.split())\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "# Create clean_text column\n",
    "df['clean_text'] = df['Resume_html'].fillna(df['Resume_str']).map(clean_resume_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fda4110c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spaCy model loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Make sure you have installed the model once in your venv:\n",
    "# !python -m spacy download en_core_web_sm\n",
    "\n",
    "import spacy\n",
    "\n",
    "try:\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    print(\"spaCy model loaded successfully.\")\n",
    "except OSError:\n",
    "    print(\"spaCy model not found. Please run:\")\n",
    "    print(\"    !python -m spacy download en_core_web_sm\")\n",
    "    raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d7eed3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2710/2710 [00:00<00:00, 48987.26it/s]\n"
     ]
    }
   ],
   "source": [
    "# Regex patterns\n",
    "email_re = re.compile(r'([A-Za-z0-9\\._%+\\-]+@[A-Za-z0-9\\.\\-]+\\.[A-Za-z]{2,})', re.I)\n",
    "phone_re = re.compile(r'(\\+?\\d[\\d\\-\\s\\(\\)]{6,}\\d)')\n",
    "linkedin_re = re.compile(r'(https?://(?:www\\.)?linkedin\\.com/[^\\s,;]+)', re.I)\n",
    "github_re = re.compile(r'(https?://(?:www\\.)?github\\.com/[^\\s,;]+)', re.I)\n",
    "\n",
    "def extract_contacts(text):\n",
    "    if not isinstance(text, str):\n",
    "        return {'emails': [], 'phones': [], 'linkedin': [], 'github': []}\n",
    "    \n",
    "    emails = list(dict.fromkeys(email_re.findall(text)))\n",
    "    phones = []\n",
    "    for p in phone_re.findall(text):\n",
    "        digits = re.sub(r'\\D', '', p)\n",
    "        if 7 <= len(digits) <= 15:\n",
    "            phones.append(p.strip())\n",
    "    phones = list(dict.fromkeys(phones))\n",
    "    \n",
    "    linkedin = list(dict.fromkeys(linkedin_re.findall(text)))\n",
    "    github = list(dict.fromkeys(github_re.findall(text)))\n",
    "    \n",
    "    return {'emails': emails, 'phones': phones, 'linkedin': linkedin, 'github': github}\n",
    "\n",
    "# Apply contact extraction\n",
    "df['contacts'] = df['clean_text'].progress_map(extract_contacts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a9bde0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2710/2710 [00:00<00:00, 434086.84it/s]\n"
     ]
    }
   ],
   "source": [
    "# Name extraction: spaCy + regex fallback\n",
    "name_line_re = re.compile(r'^[A-Z][a-z]+(?:[\\s\\-][A-Z][a-z]+){1,3}$')\n",
    "\n",
    "def extract_name(text):\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return None\n",
    "    \n",
    "    snippet = text[:600]  # first 600 chars\n",
    "    # spaCy NER\n",
    "    doc = nlp(snippet)\n",
    "    persons = [ent.text.strip() for ent in doc.ents if ent.label_ == \"PERSON\"]\n",
    "    if persons:\n",
    "        return persons[0]\n",
    "    \n",
    "    # First line heuristic\n",
    "    lines = snippet.split(\"\\n\")\n",
    "    if lines:\n",
    "        first = lines[0].strip()\n",
    "        if 2 <= len(first.split()) <= 4 and name_line_re.match(first):\n",
    "            return first\n",
    "    return None\n",
    "\n",
    "# Apply name extraction\n",
    "df['name'] = df['clean_text'].progress_map(extract_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbef7fe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total resumes: 2710\n",
      "Resumes with name: 0 (0.0%)\n",
      "Resumes with ≥1 email: 0 (0.0%)\n",
      "Resumes with ≥1 phone: 0 (0.0%)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>contacts</th>\n",
       "      <th>Category</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [name, contacts, Category, clean_text]\n",
       "Index: []"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>contacts</th>\n",
       "      <th>Category</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>{'emails': [], 'phones': [], 'linkedin': [], '...</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>{'emails': [], 'phones': [], 'linkedin': [], '...</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>{'emails': [], 'phones': [], 'linkedin': [], '...</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>{'emails': [], 'phones': [], 'linkedin': [], '...</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>{'emails': [], 'phones': [], 'linkedin': [], '...</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>None</td>\n",
       "      <td>{'emails': [], 'phones': [], 'linkedin': [], '...</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>None</td>\n",
       "      <td>{'emails': [], 'phones': [], 'linkedin': [], '...</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>None</td>\n",
       "      <td>{'emails': [], 'phones': [], 'linkedin': [], '...</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>None</td>\n",
       "      <td>{'emails': [], 'phones': [], 'linkedin': [], '...</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>None</td>\n",
       "      <td>{'emails': [], 'phones': [], 'linkedin': [], '...</td>\n",
       "      <td>None</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   name                                           contacts Category clean_text\n",
       "0  None  {'emails': [], 'phones': [], 'linkedin': [], '...     None           \n",
       "1  None  {'emails': [], 'phones': [], 'linkedin': [], '...     None           \n",
       "2  None  {'emails': [], 'phones': [], 'linkedin': [], '...     None           \n",
       "3  None  {'emails': [], 'phones': [], 'linkedin': [], '...     None           \n",
       "4  None  {'emails': [], 'phones': [], 'linkedin': [], '...     None           \n",
       "5  None  {'emails': [], 'phones': [], 'linkedin': [], '...     None           \n",
       "6  None  {'emails': [], 'phones': [], 'linkedin': [], '...     None           \n",
       "7  None  {'emails': [], 'phones': [], 'linkedin': [], '...     None           \n",
       "8  None  {'emails': [], 'phones': [], 'linkedin': [], '...     None           \n",
       "9  None  {'emails': [], 'phones': [], 'linkedin': [], '...     None           "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved parsed resumes to: C:\\Users\\abanu\\Documents\\T-IQ\\data\\processed\\resumes_parsed.csv\n"
     ]
    }
   ],
   "source": [
    "# Summary\n",
    "total = len(df)\n",
    "rows_with_name = df['name'].notna().sum()\n",
    "rows_with_email = df['contacts'].map(lambda c: len(c.get('emails',[]))>0).sum()\n",
    "rows_with_phone = df['contacts'].map(lambda c: len(c.get('phones',[]))>0).sum()\n",
    "\n",
    "print(f\"Total resumes: {total}\")\n",
    "print(f\"Resumes with name: {rows_with_name} ({rows_with_name/total:.1%})\")\n",
    "print(f\"Resumes with ≥1 email: {rows_with_email} ({rows_with_email/total:.1%})\")\n",
    "print(f\"Resumes with ≥1 phone: {rows_with_phone} ({rows_with_phone/total:.1%})\")\n",
    "\n",
    "# Show examples\n",
    "cols_to_show = ['ID','name','contacts','Category','clean_text']\n",
    "cols_to_show = [c for c in cols_to_show if c in df.columns]\n",
    "\n",
    "display(df.loc[df['name'].notna() | df['contacts'].map(lambda c: len(c.get('emails',[]))>0), cols_to_show].head(10))\n",
    "display(df.loc[df['name'].isna() & df['contacts'].map(lambda c: len(c.get('emails',[]))==0), cols_to_show].head(10))\n",
    "\n",
    "# Save parsed CSV\n",
    "out_path = Path(r\"C:\\Users\\abanu\\Documents\\T-IQ\\data\\processed\\resumes_parsed.csv\")\n",
    "out_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "df.to_csv(out_path, index=False)\n",
    "print(\"Saved parsed resumes to:\", out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2a18beaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  clean_text\n",
       "0           \n",
       "1           \n",
       "2           \n",
       "3           \n",
       "4           "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "def clean_resume_html(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    \n",
    "    # Use BeautifulSoup to get text\n",
    "    soup = BeautifulSoup(text, \"lxml\")\n",
    "    text = soup.get_text(separator=\" \")\n",
    "    \n",
    "    # Remove leftover HTML fragments\n",
    "    text = re.sub(r\"<[^>]+>\", \" \", text)\n",
    "    text = re.sub(r\"&nbsp;\", \" \", text)\n",
    "    \n",
    "    # Remove extra whitespace and special characters\n",
    "    text = re.sub(r\"[\\•\\●\\►\\▪\\□\\·]\", \" \", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    \n",
    "    return text.strip()\n",
    "\n",
    "# Rebuild clean_text column (prefer Resume_html if it exists)\n",
    "df['clean_text'] = df['Resume_html'].fillna(df['Resume_str']).map(clean_resume_html)\n",
    "\n",
    "# Quick check\n",
    "display(df[['clean_text']].head(5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "232c129b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2710/2710 [00:00<00:00, 236650.58it/s]\n",
      "100%|██████████| 2710/2710 [00:00<00:00, 390563.30it/s]\n"
     ]
    }
   ],
   "source": [
    "# Contacts\n",
    "df['contacts'] = df['clean_text'].progress_map(extract_contacts)\n",
    "\n",
    "# Names\n",
    "df['name'] = df['clean_text'].progress_map(extract_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a4aebf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['', '', '', '', '', '', '', '', '', '']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['clean_text'].head(10).tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e143e574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Names detected: 0\n",
      "Resumes with ≥1 email: 0\n",
      "Resumes with ≥1 phone: 0\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"['ID'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mResumes with ≥1 phone:\u001b[39m\u001b[33m\"\u001b[39m, df[\u001b[33m'\u001b[39m\u001b[33mcontacts\u001b[39m\u001b[33m'\u001b[39m].map(\u001b[38;5;28;01mlambda\u001b[39;00m c: \u001b[38;5;28mlen\u001b[39m(c.get(\u001b[33m'\u001b[39m\u001b[33mphones\u001b[39m\u001b[33m'\u001b[39m,[]))>\u001b[32m0\u001b[39m).sum())\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Show a few examples\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m display(\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mID\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mname\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcontacts\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mCategory\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mclean_text\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m.head(\u001b[32m10\u001b[39m))\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\abanu\\Documents\\T-IQ\\venv\\Lib\\site-packages\\pandas\\core\\frame.py:4119\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4117\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[32m   4118\u001b[39m         key = \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[32m-> \u001b[39m\u001b[32m4119\u001b[39m     indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcolumns\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m]\n\u001b[32m   4121\u001b[39m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[32m   4122\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) == \u001b[38;5;28mbool\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\abanu\\Documents\\T-IQ\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6212\u001b[39m, in \u001b[36mIndex._get_indexer_strict\u001b[39m\u001b[34m(self, key, axis_name)\u001b[39m\n\u001b[32m   6209\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6210\u001b[39m     keyarr, indexer, new_indexer = \u001b[38;5;28mself\u001b[39m._reindex_non_unique(keyarr)\n\u001b[32m-> \u001b[39m\u001b[32m6212\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6214\u001b[39m keyarr = \u001b[38;5;28mself\u001b[39m.take(indexer)\n\u001b[32m   6215\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[32m   6216\u001b[39m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\abanu\\Documents\\T-IQ\\venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:6264\u001b[39m, in \u001b[36mIndex._raise_if_missing\u001b[39m\u001b[34m(self, key, indexer, axis_name)\u001b[39m\n\u001b[32m   6261\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   6263\u001b[39m not_found = \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask.nonzero()[\u001b[32m0\u001b[39m]].unique())\n\u001b[32m-> \u001b[39m\u001b[32m6264\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m not in index\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyError\u001b[39m: \"['ID'] not in index\""
     ]
    }
   ],
   "source": [
    "# How many names and emails were extracted\n",
    "print(\"Names detected:\", df['name'].notna().sum())\n",
    "print(\"Resumes with ≥1 email:\", df['contacts'].map(lambda c: len(c.get('emails',[]))>0).sum())\n",
    "print(\"Resumes with ≥1 phone:\", df['contacts'].map(lambda c: len(c.get('phones',[]))>0).sum())\n",
    "\n",
    "# Show a few examples\n",
    "display(df[['ID','name','contacts','Category','clean_text']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "33b27f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['employee_id', 'resume_text', 'resume_html', 'resume_category', 'Unnamed: 4', 'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8', 'Unnamed: 9', 'Unnamed: 10', 'Unnamed: 11', 'Unnamed: 12', 'Unnamed: 13', 'Unnamed: 14', 'Unnamed: 15', 'Unnamed: 16', 'Unnamed: 17', 'Unnamed: 18', 'Unnamed: 19', 'Unnamed: 20', 'Unnamed: 21', 'Unnamed: 22', 'Unnamed: 23', 'Unnamed: 24', 'Unnamed: 25', 'Unnamed: 26', 'Unnamed: 27', 'Unnamed: 28', 'Unnamed: 29', 'Unnamed: 30', 'Unnamed: 31', 'Unnamed: 32', 'Unnamed: 33', 'Unnamed: 34', 'Unnamed: 35', 'Unnamed: 36', 'Unnamed: 37', 'Unnamed: 38', 'Unnamed: 39', 'Unnamed: 40', 'Unnamed: 41', 'Unnamed: 42', 'Unnamed: 43', 'Unnamed: 44', 'Unnamed: 45', 'Unnamed: 46', 'Unnamed: 47', 'Unnamed: 48', 'Unnamed: 49', 'Unnamed: 50', 'Unnamed: 51', 'Unnamed: 52', 'Unnamed: 53', 'Unnamed: 54', 'Unnamed: 55', 'Unnamed: 56', 'Unnamed: 57', 'Unnamed: 58', 'Unnamed: 59', 'Unnamed: 60', 'Unnamed: 61', 'Unnamed: 62', 'Unnamed: 63', 'Unnamed: 64', 'Unnamed: 65', 'Unnamed: 66', 'Unnamed: 67', 'Unnamed: 68', 'Unnamed: 69', 'Unnamed: 70', 'Unnamed: 71', 'Unnamed: 72', 'Unnamed: 73', 'Unnamed: 74', 'Unnamed: 75', 'Unnamed: 76', 'Unnamed: 77', 'Unnamed: 78', 'Unnamed: 79', 'Unnamed: 80', 'Unnamed: 81', 'Unnamed: 82', 'Unnamed: 83', 'Unnamed: 84', 'Unnamed: 85', 'Unnamed: 86', 'Unnamed: 87', 'Unnamed: 88', 'Unnamed: 89', 'Unnamed: 90', 'Unnamed: 91', 'Unnamed: 92', 'Unnamed: 93', 'Unnamed: 94', 'Unnamed: 95', 'Unnamed: 96', 'Unnamed: 97', 'Unnamed: 98', 'Unnamed: 99', 'Unnamed: 100', 'Unnamed: 101', 'Unnamed: 102', 'Unnamed: 103', 'Unnamed: 104', 'Unnamed: 105', 'Unnamed: 106', 'Unnamed: 107', 'Unnamed: 108', 'Unnamed: 109', 'Unnamed: 110', 'Unnamed: 111', 'Unnamed: 112', 'Unnamed: 113', 'Unnamed: 114', 'Unnamed: 115', 'Unnamed: 116', 'Unnamed: 117', 'Unnamed: 118', 'Unnamed: 119', 'Unnamed: 120', 'Unnamed: 121', 'Unnamed: 122', 'Unnamed: 123', 'Unnamed: 124', 'Unnamed: 125', 'Unnamed: 126', 'Unnamed: 127', 'Unnamed: 128', 'Unnamed: 129', 'Unnamed: 130', 'Unnamed: 131', 'Unnamed: 132', 'Unnamed: 133', 'Unnamed: 134', 'Unnamed: 135', 'Unnamed: 136', 'Unnamed: 137', 'Unnamed: 138', 'Unnamed: 139', 'Unnamed: 140', 'Unnamed: 141', 'Unnamed: 142', 'Unnamed: 143', 'Unnamed: 144', 'Unnamed: 145', 'Unnamed: 146', 'Unnamed: 147', 'Unnamed: 148', 'Unnamed: 149', 'Unnamed: 150', 'Unnamed: 151', 'Unnamed: 152', 'Unnamed: 153', 'Unnamed: 154', 'Unnamed: 155', 'Unnamed: 156', 'Unnamed: 157', 'Unnamed: 158', 'Unnamed: 159', 'Unnamed: 160', 'Unnamed: 161', 'Unnamed: 162', 'Unnamed: 163', 'Unnamed: 164', 'Unnamed: 165', 'Unnamed: 166', 'Unnamed: 167', 'Unnamed: 168', 'Resume_str', 'Resume_html', 'Category', 'len_text', 'clean_text', 'contacts', 'name']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "30e3c7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns={'employee_id': 'ID',\n",
    "                        'resume_text': 'Resume_str',\n",
    "                        'resume_html': 'Resume_html',\n",
    "                        'resume_category': 'Category'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "24433eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[[c for c in df.columns if not c.startswith('Unnamed:')]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "142f5b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ID', 'Resume_str', 'Resume_str', 'Resume_html', 'Resume_html', 'Category', 'Category', 'Resume_str', 'Resume_str', 'Resume_html', 'Resume_html', 'Category', 'Category', 'len_text', 'clean_text', 'contacts', 'name']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.tolist())\n",
    "# Expected: ['ID','Resume_str','Resume_html','Category','len_text','clean_text','contacts','name']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a411f65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ID', 'Resume_str', 'Resume_str', 'Resume_str', 'Resume_str', 'Resume_html', 'Resume_html', 'Resume_html', 'Resume_html', 'Category', 'Category', 'Category', 'Category', 'len_text', 'clean_text', 'contacts', 'name']\n"
     ]
    }
   ],
   "source": [
    "# Keep only the **first occurrence** of each useful column\n",
    "cols_to_keep = ['ID', 'Resume_str', 'Resume_html', 'Category', 'len_text', 'clean_text', 'contacts', 'name']\n",
    "\n",
    "# Deduplicate columns: take the first occurrence\n",
    "seen = set()\n",
    "new_cols = []\n",
    "for c in df.columns:\n",
    "    if c in cols_to_keep and c not in seen:\n",
    "        new_cols.append(c)\n",
    "        seen.add(c)\n",
    "\n",
    "df = df[new_cols]\n",
    "\n",
    "# Reset column order to expected\n",
    "df = df[['ID', 'Resume_str', 'Resume_html', 'Category', 'len_text', 'clean_text', 'contacts', 'name']]\n",
    "\n",
    "# Confirm\n",
    "print(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e0360b8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ID', 'Resume_str', 'Resume_str', 'Resume_str', 'Resume_str', 'Resume_html', 'Resume_html', 'Resume_html', 'Resume_html', 'Category', 'Category', 'Category', 'Category', 'len_text', 'clean_text', 'contacts', 'name']\n"
     ]
    }
   ],
   "source": [
    "# List of essential columns\n",
    "essential_cols = ['ID', 'Resume_str', 'Resume_html', 'Category', 'len_text', 'clean_text', 'contacts', 'name']\n",
    "\n",
    "# Keep only the first occurrence of each essential column\n",
    "seen = set()\n",
    "cols_to_keep = []\n",
    "for c in df.columns:\n",
    "    if c in essential_cols and c not in seen:\n",
    "        cols_to_keep.append(c)\n",
    "        seen.add(c)\n",
    "\n",
    "df = df[cols_to_keep]\n",
    "\n",
    "# Check the result\n",
    "print(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8e8db727",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "read_csv() got an unexpected keyword argument 'mangle_dupe_cols'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Load CSV with automatic duplicate handling\u001b[39;00m\n\u001b[32m      4\u001b[39m csv_path = \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mC:\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mUsers\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mabanu\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mDocuments\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mT-IQ\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mraw\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mresumes\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mResume\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mResume.csv\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcsv_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmangle_dupe_cols\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Inspect columns\u001b[39;00m\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(df.columns.tolist())\n",
      "\u001b[31mTypeError\u001b[39m: read_csv() got an unexpected keyword argument 'mangle_dupe_cols'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load CSV with automatic duplicate handling\n",
    "csv_path = r\"C:\\Users\\abanu\\Documents\\T-IQ\\data\\raw\\resumes\\Resume\\Resume.csv\"\n",
    "df = pd.read_csv(csv_path, mangle_dupe_cols=True)\n",
    "\n",
    "# Inspect columns\n",
    "print(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "711c4df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['employee_id', 'resume_text', 'resume_html', 'resume_category', 'Unnamed: 4', 'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7', 'Unnamed: 8', 'Unnamed: 9', 'Unnamed: 10', 'Unnamed: 11', 'Unnamed: 12', 'Unnamed: 13', 'Unnamed: 14', 'Unnamed: 15', 'Unnamed: 16', 'Unnamed: 17', 'Unnamed: 18', 'Unnamed: 19', 'Unnamed: 20', 'Unnamed: 21', 'Unnamed: 22', 'Unnamed: 23', 'Unnamed: 24', 'Unnamed: 25', 'Unnamed: 26', 'Unnamed: 27', 'Unnamed: 28', 'Unnamed: 29', 'Unnamed: 30', 'Unnamed: 31', 'Unnamed: 32', 'Unnamed: 33', 'Unnamed: 34', 'Unnamed: 35', 'Unnamed: 36', 'Unnamed: 37', 'Unnamed: 38', 'Unnamed: 39', 'Unnamed: 40', 'Unnamed: 41', 'Unnamed: 42', 'Unnamed: 43', 'Unnamed: 44', 'Unnamed: 45', 'Unnamed: 46', 'Unnamed: 47', 'Unnamed: 48', 'Unnamed: 49', 'Unnamed: 50', 'Unnamed: 51', 'Unnamed: 52', 'Unnamed: 53', 'Unnamed: 54', 'Unnamed: 55', 'Unnamed: 56', 'Unnamed: 57', 'Unnamed: 58', 'Unnamed: 59', 'Unnamed: 60', 'Unnamed: 61', 'Unnamed: 62', 'Unnamed: 63', 'Unnamed: 64', 'Unnamed: 65', 'Unnamed: 66', 'Unnamed: 67', 'Unnamed: 68', 'Unnamed: 69', 'Unnamed: 70', 'Unnamed: 71', 'Unnamed: 72', 'Unnamed: 73', 'Unnamed: 74', 'Unnamed: 75', 'Unnamed: 76', 'Unnamed: 77', 'Unnamed: 78', 'Unnamed: 79', 'Unnamed: 80', 'Unnamed: 81', 'Unnamed: 82', 'Unnamed: 83', 'Unnamed: 84', 'Unnamed: 85', 'Unnamed: 86', 'Unnamed: 87', 'Unnamed: 88', 'Unnamed: 89', 'Unnamed: 90', 'Unnamed: 91', 'Unnamed: 92', 'Unnamed: 93', 'Unnamed: 94', 'Unnamed: 95', 'Unnamed: 96', 'Unnamed: 97', 'Unnamed: 98', 'Unnamed: 99', 'Unnamed: 100', 'Unnamed: 101', 'Unnamed: 102', 'Unnamed: 103', 'Unnamed: 104', 'Unnamed: 105', 'Unnamed: 106', 'Unnamed: 107', 'Unnamed: 108', 'Unnamed: 109', 'Unnamed: 110', 'Unnamed: 111', 'Unnamed: 112', 'Unnamed: 113', 'Unnamed: 114', 'Unnamed: 115', 'Unnamed: 116', 'Unnamed: 117', 'Unnamed: 118', 'Unnamed: 119', 'Unnamed: 120', 'Unnamed: 121', 'Unnamed: 122', 'Unnamed: 123', 'Unnamed: 124', 'Unnamed: 125', 'Unnamed: 126', 'Unnamed: 127', 'Unnamed: 128', 'Unnamed: 129', 'Unnamed: 130', 'Unnamed: 131', 'Unnamed: 132', 'Unnamed: 133', 'Unnamed: 134', 'Unnamed: 135', 'Unnamed: 136', 'Unnamed: 137', 'Unnamed: 138', 'Unnamed: 139', 'Unnamed: 140', 'Unnamed: 141', 'Unnamed: 142', 'Unnamed: 143', 'Unnamed: 144', 'Unnamed: 145', 'Unnamed: 146', 'Unnamed: 147', 'Unnamed: 148', 'Unnamed: 149', 'Unnamed: 150', 'Unnamed: 151', 'Unnamed: 152', 'Unnamed: 153', 'Unnamed: 154', 'Unnamed: 155', 'Unnamed: 156', 'Unnamed: 157', 'Unnamed: 158', 'Unnamed: 159', 'Unnamed: 160', 'Unnamed: 161', 'Unnamed: 162', 'Unnamed: 163', 'Unnamed: 164', 'Unnamed: 165', 'Unnamed: 166', 'Unnamed: 167', 'Unnamed: 168']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_path = r\"C:\\Users\\abanu\\Documents\\T-IQ\\data\\raw\\resumes\\Resume\\Resume.csv\"\n",
    "\n",
    "# Load CSV\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# Inspect columns\n",
    "print(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "50a775e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ID', 'Resume_str', 'Resume_html', 'Category', 'len_text', 'clean_text', 'contacts', 'name']\n"
     ]
    }
   ],
   "source": [
    "# Keep the first occurrence of each essential column\n",
    "essential_cols = ['employee_id', 'resume_text', 'resume_html', 'resume_category']\n",
    "\n",
    "seen = set()\n",
    "cols_to_keep = []\n",
    "for c in df.columns:\n",
    "    if c in essential_cols and c not in seen:\n",
    "        cols_to_keep.append(c)\n",
    "        seen.add(c)\n",
    "\n",
    "df = df[cols_to_keep]\n",
    "\n",
    "# Rename to standard names\n",
    "df = df.rename(columns={\n",
    "    'employee_id': 'ID',\n",
    "    'resume_text': 'Resume_str',\n",
    "    'resume_html': 'Resume_html',\n",
    "    'resume_category': 'Category'\n",
    "})\n",
    "\n",
    "# Add downstream columns if missing\n",
    "for c in ['len_text','clean_text','contacts','name']:\n",
    "    if c not in df.columns:\n",
    "        df[c] = None\n",
    "\n",
    "# Confirm final columns\n",
    "print(df.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "901d8131",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "\n",
    "def clean_resume_html(text):\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "    soup = BeautifulSoup(text, \"lxml\")\n",
    "    text = soup.get_text(separator=\" \")\n",
    "    text = re.sub(r\"<[^>]+>\", \" \", text)\n",
    "    text = re.sub(r\"&nbsp;\", \" \", text)\n",
    "    text = re.sub(r\"[\\•\\●\\►\\▪\\□\\·]\", \" \", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "    return text.strip()\n",
    "\n",
    "df['clean_text'] = df['Resume_html'].fillna(df['Resume_str']).map(clean_resume_html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "be20ad50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2710/2710 [00:01<00:00, 1663.41it/s]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "def extract_contacts(text):\n",
    "    contacts = {\n",
    "        'emails': re.findall(r\"[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\\.[a-z]{2,}\", text),\n",
    "        'phones': re.findall(r\"\\+?\\d[\\d\\s\\-]{7,}\\d\", text),\n",
    "        'linkedin': re.findall(r\"(https?://www\\.linkedin\\.com/in/[a-zA-Z0-9_-]+)\", text)\n",
    "    }\n",
    "    return contacts\n",
    "\n",
    "df['contacts'] = df['clean_text'].progress_map(extract_contacts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "80626fcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2710/2710 [01:13<00:00, 36.98it/s] \n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Download model if not already\n",
    "# !python -m spacy download en_core_web_sm\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def extract_name(text):\n",
    "    if not text: \n",
    "        return None\n",
    "    doc = nlp(text[:1000])  # limit to first 1000 chars\n",
    "    for ent in doc.ents:\n",
    "        if ent.label_ == 'PERSON':\n",
    "            return ent.text\n",
    "    # fallback: take first line with 2-4 words\n",
    "    lines = text.splitlines()\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if 2 <= len(line.split()) <= 4:\n",
    "            return line\n",
    "    return None\n",
    "\n",
    "df['name'] = df['clean_text'].progress_map(extract_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "092c5842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Names detected: 1727\n",
      "Resumes with ≥1 email: 18\n",
      "Resumes with ≥1 phone: 442\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>name</th>\n",
       "      <th>contacts</th>\n",
       "      <th>Category</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16852973</td>\n",
       "      <td>Highlights Focused</td>\n",
       "      <td>{'emails': [], 'phones': [], 'linkedin': []}</td>\n",
       "      <td>HR</td>\n",
       "      <td>HR ADMINISTRATOR/MARKETING ASSOCIATE HR ADMINI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22323967</td>\n",
       "      <td>Served</td>\n",
       "      <td>{'emails': [], 'phones': [], 'linkedin': []}</td>\n",
       "      <td>HR</td>\n",
       "      <td>HR SPECIALIST, US HR OPERATIONS Summary Versat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33176873</td>\n",
       "      <td>ASHHRA</td>\n",
       "      <td>{'emails': [], 'phones': [], 'linkedin': []}</td>\n",
       "      <td>HR</td>\n",
       "      <td>HR DIRECTOR Summary Over 20 years experience i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27018550</td>\n",
       "      <td>None</td>\n",
       "      <td>{'emails': [], 'phones': [], 'linkedin': []}</td>\n",
       "      <td>HR</td>\n",
       "      <td>HR SPECIALIST Summary Dedicated, Driven, and D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17812897</td>\n",
       "      <td>Skill Highlights</td>\n",
       "      <td>{'emails': [], 'phones': [], 'linkedin': []}</td>\n",
       "      <td>HR</td>\n",
       "      <td>HR MANAGER Skill Highlights HR SKILLS HR Depar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>11592605</td>\n",
       "      <td>Maintained</td>\n",
       "      <td>{'emails': [], 'phones': [], 'linkedin': []}</td>\n",
       "      <td>HR</td>\n",
       "      <td>HR GENERALIST Summary Dedicated and focused Ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>25824789</td>\n",
       "      <td>Mandated Training</td>\n",
       "      <td>{'emails': [], 'phones': [], 'linkedin': []}</td>\n",
       "      <td>HR</td>\n",
       "      <td>HR MANAGER Summary HUMAN RESOURCES MANAGER Ext...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>15375009</td>\n",
       "      <td>management, vendor</td>\n",
       "      <td>{'emails': [], 'phones': [], 'linkedin': []}</td>\n",
       "      <td>HR</td>\n",
       "      <td>HR MANAGER Professional Summary Senior HR prof...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11847784</td>\n",
       "      <td>None</td>\n",
       "      <td>{'emails': [], 'phones': [], 'linkedin': []}</td>\n",
       "      <td>HR</td>\n",
       "      <td>HR SPECIALIST Summary Possess 15+ years of exp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>32896934</td>\n",
       "      <td>None</td>\n",
       "      <td>{'emails': [], 'phones': [], 'linkedin': []}</td>\n",
       "      <td>HR</td>\n",
       "      <td>HR CLERK Summary Translates business vision in...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID                name                                      contacts  \\\n",
       "0  16852973  Highlights Focused  {'emails': [], 'phones': [], 'linkedin': []}   \n",
       "1  22323967              Served  {'emails': [], 'phones': [], 'linkedin': []}   \n",
       "2  33176873              ASHHRA  {'emails': [], 'phones': [], 'linkedin': []}   \n",
       "3  27018550                None  {'emails': [], 'phones': [], 'linkedin': []}   \n",
       "4  17812897    Skill Highlights  {'emails': [], 'phones': [], 'linkedin': []}   \n",
       "5  11592605          Maintained  {'emails': [], 'phones': [], 'linkedin': []}   \n",
       "6  25824789   Mandated Training  {'emails': [], 'phones': [], 'linkedin': []}   \n",
       "7  15375009  management, vendor  {'emails': [], 'phones': [], 'linkedin': []}   \n",
       "8  11847784                None  {'emails': [], 'phones': [], 'linkedin': []}   \n",
       "9  32896934                None  {'emails': [], 'phones': [], 'linkedin': []}   \n",
       "\n",
       "  Category                                         clean_text  \n",
       "0       HR  HR ADMINISTRATOR/MARKETING ASSOCIATE HR ADMINI...  \n",
       "1       HR  HR SPECIALIST, US HR OPERATIONS Summary Versat...  \n",
       "2       HR  HR DIRECTOR Summary Over 20 years experience i...  \n",
       "3       HR  HR SPECIALIST Summary Dedicated, Driven, and D...  \n",
       "4       HR  HR MANAGER Skill Highlights HR SKILLS HR Depar...  \n",
       "5       HR  HR GENERALIST Summary Dedicated and focused Ad...  \n",
       "6       HR  HR MANAGER Summary HUMAN RESOURCES MANAGER Ext...  \n",
       "7       HR  HR MANAGER Professional Summary Senior HR prof...  \n",
       "8       HR  HR SPECIALIST Summary Possess 15+ years of exp...  \n",
       "9       HR  HR CLERK Summary Translates business vision in...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# How many rows have names, emails, phones\n",
    "print(\"Names detected:\", df['name'].notna().sum())\n",
    "print(\"Resumes with ≥1 email:\", df['contacts'].map(lambda c: len(c['emails'])>0).sum())\n",
    "print(\"Resumes with ≥1 phone:\", df['contacts'].map(lambda c: len(c['phones'])>0).sum())\n",
    "\n",
    "# Show a few examples\n",
    "display(df[['ID','name','contacts','Category','clean_text']].head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "046bf3ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Processed CSV saved.\n"
     ]
    }
   ],
   "source": [
    "output_path = r\"C:\\Users\\abanu\\Documents\\T-IQ\\data\\processed\\resumes_parsed.csv\"\n",
    "df.to_csv(output_path, index=False)\n",
    "print(\"✅ Processed CSV saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239eaed9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
